{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meenusj/deepfake-detection/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmAlLJUBdGQO",
        "outputId": "a0fa2374-efc4-479b-bc92-502f97c859ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext) (2.11.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1bt9O0kXVck4",
        "outputId": "19188520-9465-4dee-c695-c334520a4fcc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1218/1218 [==============================] - 6s 4ms/step\n",
            "New Dataset Evaluation Metrics:\n",
            "Accuracy: 0.9344\n",
            "Precision: 0.8730\n",
            "Recall: 0.9344\n",
            "F1 Score: 0.9027\n",
            "Confusion Matrix for the New Dataset:\n",
            "[[    0     0     0     0   384]\n",
            " [    0     0     0     0  1278]\n",
            " [    0     0     0     0   484]\n",
            " [    0     0     0     0   412]\n",
            " [    0     0     0     0 36412]]\n",
            "Classification Report for the New Dataset:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       384\n",
            "           1       0.00      0.00      0.00      1278\n",
            "           2       0.00      0.00      0.00       484\n",
            "           3       0.00      0.00      0.00       412\n",
            "           4       0.93      1.00      0.97     36412\n",
            "\n",
            "    accuracy                           0.93     38970\n",
            "   macro avg       0.19      0.20      0.19     38970\n",
            "weighted avg       0.87      0.93      0.90     38970\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import load_model\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import fasttext\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "\n",
        "# Load the FastText model\n",
        "model = fasttext.load_model('cc.en.300.bin')\n",
        "\n",
        "\n",
        "# Assuming the correct column name is 'text', replace 'tweet_text' with the actual name\n",
        "def preprocess(text):\n",
        "    # Tokenization\n",
        "    tokens = text.split()\n",
        "\n",
        "    # Case conversion\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "\n",
        "    # Remove hashtags and usernames\n",
        "    tokens = [re.sub(r'#\\w+|@\\w+', '', word) for word in tokens]\n",
        "\n",
        "    # Remove punctuation\n",
        "    tokens = [word for word in tokens if word.isalnum()]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Load the pre-trained CNN model\n",
        "loaded_model = load_model('deepfake_model.h5')\n",
        "\n",
        "# Load the label encoder\n",
        "with open('label_encoder.pkl', 'rb') as le_file:\n",
        "    label_encoder = pickle.load(le_file)\n",
        "\n",
        "\n",
        "\n",
        "# Load your new dataset (replace 'new_test.csv' with your actual dataset file)\n",
        "new_csv_file_path = 'test.csv'\n",
        "new_df = pd.read_csv(new_csv_file_path, delimiter=';')\n",
        "\n",
        "# Preprocess the text in the 'text' column\n",
        "new_df['preprocessed_text'] = new_df['text'].apply(preprocess)\n",
        "\n",
        "# Tokenize the text\n",
        "new_tokenized_text = [word_tokenize(text) for text in new_df['preprocessed_text']]\n",
        "\n",
        "# Get word vectors for each token using the pre-trained FastText model\n",
        "new_word_vectors = [model.get_word_vector(word) for tokens in new_tokenized_text for word in tokens]\n",
        "\n",
        "# Convert word vectors to DataFrame\n",
        "new_word_vectors_df = pd.DataFrame(new_word_vectors, columns=[f'feature_{i}' for i in range(300)])\n",
        "\n",
        "# Concatenate the original DataFrame with the word vectors DataFrame\n",
        "new_df_with_vectors = pd.concat([new_df, new_word_vectors_df], axis=1)\n",
        "\n",
        "# Extract feature columns (assuming they start from column 'feature_0')\n",
        "new_feature_columns = new_df_with_vectors.columns[new_df_with_vectors.columns.str.startswith('feature_')]\n",
        "\n",
        "# Extract features and labels\n",
        "new_X = new_df_with_vectors[new_feature_columns].values\n",
        "new_y_actual = label_encoder.transform(new_df_with_vectors['class_type'])\n",
        "\n",
        "# Reshape the input data to be compatible with Conv1D layer\n",
        "new_X = new_X.reshape(new_X.shape[0], new_X.shape[1], 1)\n",
        "\n",
        "# Predict on the new dataset\n",
        "new_y_pred_probs = loaded_model.predict(new_X)\n",
        "new_y_pred_classes = new_y_pred_probs.argmax(axis=-1)\n",
        "\n",
        "# Calculate evaluation metrics for the new dataset\n",
        "new_accuracy = accuracy_score(new_y_actual, new_y_pred_classes)\n",
        "new_precision = precision_score(new_y_actual, new_y_pred_classes, average='weighted')\n",
        "new_recall = recall_score(new_y_actual, new_y_pred_classes, average='weighted')\n",
        "new_f1 = f1_score(new_y_actual, new_y_pred_classes, average='weighted')\n",
        "\n",
        "# Print the evaluation metrics for the new dataset\n",
        "print(f\"New Dataset Evaluation Metrics:\")\n",
        "print(f\"Accuracy: {new_accuracy:.4f}\")\n",
        "print(f\"Precision: {new_precision:.4f}\")\n",
        "print(f\"Recall: {new_recall:.4f}\")\n",
        "print(f\"F1 Score: {new_f1:.4f}\")\n",
        "\n",
        "# Create a confusion matrix for the new dataset\n",
        "new_conf_matrix = confusion_matrix(new_y_actual, new_y_pred_classes)\n",
        "\n",
        "# Print the confusion matrix for the new dataset\n",
        "print(\"Confusion Matrix for the New Dataset:\")\n",
        "print(new_conf_matrix)\n",
        "\n",
        "# Create a classification report for the new dataset\n",
        "new_class_report = classification_report(new_y_actual, new_y_pred_classes)\n",
        "\n",
        "# Print the classification report for the new dataset\\]\n",
        "\n",
        "print(\"Classification Report for the New Dataset:\")\n",
        "print(new_class_report)\n",
        "\n",
        "\n",
        "# # Print actual vs predicted output\n",
        "# for actual, predicted in zip(new_y_actual, new_y_pred_classes):\n",
        "#     print(f\"Actual: {label_encoder.inverse_transform([actual])[0]}, Predicted: {label_encoder.inverse_transform([predicted])[0]}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkG/5BmWilg4Qu1kdtYBrX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}